# vector-quantize 

## focus on single codebook for 'semantic' but large

## ongoing
- [x] vq
- [x] lfq
- [ ] fsq
- [x] random quantize (in bestrq)
- [ ] rvq
- [x] [joint training with ctc in wenet xxx-formers](https://github.com/Mddct/usm-tokenizer)
- [ ] joint training with LLM-aware quantize
